{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac605650-dad1-479b-affa-ff8d828f4a50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!wget https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9965d9fa-d1bc-42c4-a900-1ea001bbf83d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense, Embedding\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b97e4b08-4a6e-40a1-a75e-e412f4c42536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor\n"
     ]
    }
   ],
   "source": [
    "# Path to the shakespeare.txt file\n",
    "file_path = 'shakespeare.txt'\n",
    "\n",
    "# Open and read the file\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    shakespeare_text = file.read()\n",
    "\n",
    "# Print the first 500 characters (optional, just to preview the content)\n",
    "print(shakespeare_text[:500])  # Adjust as needed to read more or less\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e4843e5-eddd-4233-96d4-529e6d4cfacc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = shakespeare_text\n",
    "chars = sorted(set(text))  # All unique characters\n",
    "char_to_idx = {char: idx for idx, char in enumerate(chars)}  # Mapping from char to index\n",
    "idx_to_char = {idx: char for idx, char in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f98b7a9-9003-456d-9826-e3040a7c5151",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\n': 0, ' ': 1, '!': 2, '$': 3, '&': 4, \"'\": 5, ',': 6, '-': 7, '.': 8, '3': 9, ':': 10, ';': 11, '?': 12, 'A': 13, 'B': 14, 'C': 15, 'D': 16, 'E': 17, 'F': 18, 'G': 19, 'H': 20, 'I': 21, 'J': 22, 'K': 23, 'L': 24, 'M': 25, 'N': 26, 'O': 27, 'P': 28, 'Q': 29, 'R': 30, 'S': 31, 'T': 32, 'U': 33, 'V': 34, 'W': 35, 'X': 36, 'Y': 37, 'Z': 38, 'a': 39, 'b': 40, 'c': 41, 'd': 42, 'e': 43, 'f': 44, 'g': 45, 'h': 46, 'i': 47, 'j': 48, 'k': 49, 'l': 50, 'm': 51, 'n': 52, 'o': 53, 'p': 54, 'q': 55, 'r': 56, 's': 57, 't': 58, 'u': 59, 'v': 60, 'w': 61, 'x': 62, 'y': 63, 'z': 64}\n"
     ]
    }
   ],
   "source": [
    "print(char_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a9999d4f-7450-4e38-98ab-9f0efcd3a77c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seq_length = 10  # Number of characters in each sequence\n",
    "vocab_size = len(chars)  # Size of vocabulary\n",
    "embedding_dim = 64  # Embedding dimensions\n",
    "rnn_units = 128  # Number of RNN units\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "574b8e41-26b1-40f6-b72e-fe5f08c45c01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_sequences(text, seq_length):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(text) - seq_length):\n",
    "        X.append([char_to_idx[char] for char in text[i:i + seq_length]])\n",
    "        y.append(char_to_idx[text[i + seq_length]])\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6c56492c-39ca-4ea5-8dfd-63050276eeab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18 47 56 ... 47 58 47]\n",
      " [47 56 57 ... 58 47 64]\n",
      " [56 57 58 ... 47 64 43]\n",
      " ...\n",
      " [ 1 39 56 ... 49 47 52]\n",
      " [39 56 58 ... 47 52 45]\n",
      " [56 58  1 ... 52 45  8]]\n",
      "[64 43 52 ... 45  8  0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X, y = create_sequences(text, seq_length)\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "51844228-a4d3-4b64-a1f7-23bd9c44ea6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Embedding(input_dim=vocab_size, output_dim=embedding_dim),\n",
    "    SimpleRNN(rnn_units, activation='relu'),  # ReLU activation function\n",
    "    Dense(vocab_size, activation='softmax')  # Softmax for output layer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "899ee7e1-4c5d-49b6-8328-daa1cbc3b819",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3f92a93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this if using tensorflow/keras 2.x\n",
    "\n",
    "# checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "#     filepath='model_weights_epoch_{epoch:02d}.h5',  # Save file with epoch number in the name\n",
    "#     save_weights_only=True,                         # Only save the weights, not the full model\n",
    "#     save_freq='epoch',                              # Save at the end of each epoch\n",
    "#     period=2,                                       # Save every 2 epochs\n",
    "#     verbose=1                                       # Print saving info to the console\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0f7eb789",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_weights_every_2_epochs(epoch, logs):\n",
    "    if (epoch + 1) % 2 == 0:  # Save every 2 epochs\n",
    "        model.save_weights(f'model_weights_epoch_{epoch+1}.weights.h5')\n",
    "        print(f'\\nSaved weights at epoch {epoch+1}')\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=save_weights_every_2_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d4b5825f-aadb-4b4e-8392-3d5cede53dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m  102/34856\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:09\u001b[0m 2ms/step - loss: 1.6011"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 2ms/step - loss: 1.6097\n",
      "Epoch 2/100\n",
      "\u001b[1m34847/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5936\n",
      "Saved weights at epoch 2\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 3ms/step - loss: 1.5936\n",
      "Epoch 3/100\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 2ms/step - loss: 1.5798\n",
      "Epoch 4/100\n",
      "\u001b[1m34837/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5754\n",
      "Saved weights at epoch 4\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 2ms/step - loss: 1.5754\n",
      "Epoch 5/100\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 3ms/step - loss: 1.5703\n",
      "Epoch 6/100\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5655\n",
      "Saved weights at epoch 6\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 3ms/step - loss: 1.5655\n",
      "Epoch 7/100\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 3ms/step - loss: 1.5646\n",
      "Epoch 8/100\n",
      "\u001b[1m34850/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5633\n",
      "Saved weights at epoch 8\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 2ms/step - loss: 1.5633\n",
      "Epoch 9/100\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 2ms/step - loss: 1.5601\n",
      "Epoch 10/100\n",
      "\u001b[1m34850/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5586\n",
      "Saved weights at epoch 10\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 2ms/step - loss: 1.5586\n",
      "Epoch 11/100\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 3ms/step - loss: 1.5547\n",
      "Epoch 12/100\n",
      "\u001b[1m34837/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5565\n",
      "Saved weights at epoch 12\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 3ms/step - loss: 1.5565\n",
      "Epoch 13/100\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 3ms/step - loss: 1.5527\n",
      "Epoch 14/100\n",
      "\u001b[1m34835/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5539\n",
      "Saved weights at epoch 14\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 2ms/step - loss: 1.5539\n",
      "Epoch 15/100\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 2ms/step - loss: 1.5529\n",
      "Epoch 16/100\n",
      "\u001b[1m34855/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5514\n",
      "Saved weights at epoch 16\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 3ms/step - loss: 1.5514\n",
      "Epoch 17/100\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 3ms/step - loss: 1.5537\n",
      "Epoch 18/100\n",
      "\u001b[1m34855/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5499\n",
      "Saved weights at epoch 18\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 3ms/step - loss: 1.5499\n",
      "Epoch 19/100\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 3ms/step - loss: 1.5484\n",
      "Epoch 20/100\n",
      "\u001b[1m34854/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5472\n",
      "Saved weights at epoch 20\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 3ms/step - loss: 1.5472\n",
      "Epoch 21/100\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 3ms/step - loss: 1.5459\n",
      "Epoch 22/100\n",
      "\u001b[1m34841/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5473\n",
      "Saved weights at epoch 22\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 2ms/step - loss: 1.5473\n",
      "Epoch 23/100\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 2ms/step - loss: 1.5449\n",
      "Epoch 24/100\n",
      "\u001b[1m34836/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5461\n",
      "Saved weights at epoch 24\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 3ms/step - loss: 1.5461\n",
      "Epoch 25/100\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 3ms/step - loss: 1.5449\n",
      "Epoch 26/100\n",
      "\u001b[1m34837/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5476\n",
      "Saved weights at epoch 26\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 3ms/step - loss: 1.5476\n",
      "Epoch 27/100\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 2ms/step - loss: 1.5489\n",
      "Epoch 28/100\n",
      "\u001b[1m34837/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5490\n",
      "Saved weights at epoch 28\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 2ms/step - loss: 1.5490\n",
      "Epoch 29/100\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 3ms/step - loss: 1.5467\n",
      "Epoch 30/100\n",
      "\u001b[1m34853/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5448\n",
      "Saved weights at epoch 30\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 3ms/step - loss: 1.5448\n",
      "Epoch 31/100\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 2ms/step - loss: 1.5483\n",
      "Epoch 32/100\n",
      "\u001b[1m34847/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5480\n",
      "Saved weights at epoch 32\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 3ms/step - loss: 1.5480\n",
      "Epoch 33/100\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 3ms/step - loss: 1.5488\n",
      "Epoch 34/100\n",
      "\u001b[1m34845/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5490\n",
      "Saved weights at epoch 34\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 3ms/step - loss: 1.5490\n",
      "Epoch 35/100\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 3ms/step - loss: 1.5444\n",
      "Epoch 36/100\n",
      "\u001b[1m34833/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5481\n",
      "Saved weights at epoch 36\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 2ms/step - loss: 1.5481\n",
      "Epoch 37/100\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 2ms/step - loss: 1.5493\n",
      "Epoch 38/100\n",
      "\u001b[1m34840/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5532\n",
      "Saved weights at epoch 38\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 2ms/step - loss: 1.5532\n",
      "Epoch 39/100\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 2ms/step - loss: 1.5531\n",
      "Epoch 40/100\n",
      "\u001b[1m34840/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5496\n",
      "Saved weights at epoch 40\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 2ms/step - loss: 1.5496\n",
      "Epoch 41/100\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 2ms/step - loss: 1.5513\n",
      "Epoch 42/100\n",
      "\u001b[1m34839/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5544\n",
      "Saved weights at epoch 42\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 2ms/step - loss: 1.5544\n",
      "Epoch 43/100\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 2ms/step - loss: 1.5521\n",
      "Epoch 44/100\n",
      "\u001b[1m34854/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5513\n",
      "Saved weights at epoch 44\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 2ms/step - loss: 1.5513\n",
      "Epoch 45/100\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 3ms/step - loss: 1.5503\n",
      "Epoch 46/100\n",
      "\u001b[1m34839/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5524\n",
      "Saved weights at epoch 46\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 3ms/step - loss: 1.5524\n",
      "Epoch 47/100\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 3ms/step - loss: 1.5547\n",
      "Epoch 48/100\n",
      "\u001b[1m34837/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5529\n",
      "Saved weights at epoch 48\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 2ms/step - loss: 1.5529\n",
      "Epoch 49/100\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 2ms/step - loss: 1.5531\n",
      "Epoch 50/100\n",
      "\u001b[1m34836/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5529\n",
      "Saved weights at epoch 50\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 2ms/step - loss: 1.5529\n",
      "Epoch 51/100\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 2ms/step - loss: 1.5542\n",
      "Epoch 52/100\n",
      "\u001b[1m34854/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5508\n",
      "Saved weights at epoch 52\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 2ms/step - loss: 1.5508\n",
      "Epoch 53/100\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 2ms/step - loss: 1.5546\n",
      "Epoch 54/100\n",
      "\u001b[1m34838/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5550\n",
      "Saved weights at epoch 54\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 2ms/step - loss: 1.5550\n",
      "Epoch 55/100\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 2ms/step - loss: 1.5548\n",
      "Epoch 56/100\n",
      "\u001b[1m34847/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5539\n",
      "Saved weights at epoch 56\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 2ms/step - loss: 1.5539\n",
      "Epoch 57/100\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 2ms/step - loss: 1.5514\n",
      "Epoch 58/100\n",
      "\u001b[1m34837/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5573\n",
      "Saved weights at epoch 58\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 2ms/step - loss: 1.5573\n",
      "Epoch 59/100\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 2ms/step - loss: 1.5550\n",
      "Epoch 60/100\n",
      "\u001b[1m34842/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5570\n",
      "Saved weights at epoch 60\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 2ms/step - loss: 1.5570\n",
      "Epoch 61/100\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 2ms/step - loss: 1.5595\n",
      "Epoch 62/100\n",
      "\u001b[1m34853/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5715\n",
      "Saved weights at epoch 62\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 2ms/step - loss: 1.5715\n",
      "Epoch 63/100\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 2ms/step - loss: 1.5656\n",
      "Epoch 64/100\n",
      "\u001b[1m34846/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5606\n",
      "Saved weights at epoch 64\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 2ms/step - loss: 1.5606\n",
      "Epoch 65/100\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 2ms/step - loss: 1.5596\n",
      "Epoch 66/100\n",
      "\u001b[1m34847/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5609\n",
      "Saved weights at epoch 66\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 2ms/step - loss: 1.5609\n",
      "Epoch 67/100\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 2ms/step - loss: 1.5619\n",
      "Epoch 68/100\n",
      "\u001b[1m34851/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5555\n",
      "Saved weights at epoch 68\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 2ms/step - loss: 1.5555\n",
      "Epoch 69/100\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 2ms/step - loss: 1.5586\n",
      "Epoch 70/100\n",
      "\u001b[1m34848/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5631\n",
      "Saved weights at epoch 70\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 2ms/step - loss: 1.5631\n",
      "Epoch 71/100\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 2ms/step - loss: 1.5619\n",
      "Epoch 72/100\n",
      "\u001b[1m34846/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5613\n",
      "Saved weights at epoch 72\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 2ms/step - loss: 1.5613\n",
      "Epoch 73/100\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 2ms/step - loss: 1.5657\n",
      "Epoch 74/100\n",
      "\u001b[1m34841/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5605\n",
      "Saved weights at epoch 74\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 3ms/step - loss: 1.5605\n",
      "Epoch 75/100\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 3ms/step - loss: 1.5651\n",
      "Epoch 76/100\n",
      "\u001b[1m34842/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5649\n",
      "Saved weights at epoch 76\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 3ms/step - loss: 1.5649\n",
      "Epoch 77/100\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 3ms/step - loss: 1.5601\n",
      "Epoch 78/100\n",
      "\u001b[1m34848/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5671\n",
      "Saved weights at epoch 78\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 2ms/step - loss: 1.5671\n",
      "Epoch 79/100\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 3ms/step - loss: 1.5652\n",
      "Epoch 80/100\n",
      "\u001b[1m34841/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5756\n",
      "Saved weights at epoch 80\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 3ms/step - loss: 1.5756\n",
      "Epoch 81/100\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 3ms/step - loss: 1.5711\n",
      "Epoch 82/100\n",
      "\u001b[1m34845/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5698\n",
      "Saved weights at epoch 82\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 3ms/step - loss: 1.5698\n",
      "Epoch 83/100\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 3ms/step - loss: 1.5683\n",
      "Epoch 84/100\n",
      "\u001b[1m34836/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5674\n",
      "Saved weights at epoch 84\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 3ms/step - loss: 1.5674\n",
      "Epoch 85/100\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 3ms/step - loss: 1.5720\n",
      "Epoch 86/100\n",
      "\u001b[1m34841/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5714\n",
      "Saved weights at epoch 86\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 3ms/step - loss: 1.5714\n",
      "Epoch 87/100\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 3ms/step - loss: 1.5702\n",
      "Epoch 88/100\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5716\n",
      "Saved weights at epoch 88\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 3ms/step - loss: 1.5716\n",
      "Epoch 89/100\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 3ms/step - loss: 1.5713\n",
      "Epoch 90/100\n",
      "\u001b[1m34848/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5749\n",
      "Saved weights at epoch 90\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 3ms/step - loss: 1.5749\n",
      "Epoch 91/100\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 3ms/step - loss: 1.5711\n",
      "Epoch 92/100\n",
      "\u001b[1m34850/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5783\n",
      "Saved weights at epoch 92\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 3ms/step - loss: 1.5783\n",
      "Epoch 93/100\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 3ms/step - loss: 1.5793\n",
      "Epoch 94/100\n",
      "\u001b[1m34846/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5724\n",
      "Saved weights at epoch 94\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 3ms/step - loss: 1.5724\n",
      "Epoch 95/100\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 3ms/step - loss: 1.5757\n",
      "Epoch 96/100\n",
      "\u001b[1m34839/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5721\n",
      "Saved weights at epoch 96\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 3ms/step - loss: 1.5721\n",
      "Epoch 97/100\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 3ms/step - loss: 1.5728\n",
      "Epoch 98/100\n",
      "\u001b[1m34854/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5769\n",
      "Saved weights at epoch 98\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 3ms/step - loss: 1.5769\n",
      "Epoch 99/100\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 3ms/step - loss: 1.5786\n",
      "Epoch 100/100\n",
      "\u001b[1m34840/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5763\n",
      "Saved weights at epoch 100\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 3ms/step - loss: 1.5763\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f218f967800>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, batch_size=batch_size, epochs=100, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a6b9d96d-961a-4870-a3bb-59830247c094",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_rnn_model.keras') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "eec03bf4-7b0e-47e4-b511-423f96e35344",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string, gen_length=40, temperature=0.01):\n",
    "    # Convert start_string to numbers (vectorize)\n",
    "    input_eval = [char_to_idx[char] for char in start_string]\n",
    "    input_eval = np.expand_dims(input_eval, 0)  # Add batch dimension\n",
    "\n",
    "    generated_text = []\n",
    "\n",
    "    for i in range(gen_length):\n",
    "        # Get predictions for the current input sequence\n",
    "        predictions = model(input_eval)\n",
    "\n",
    "        # Remove the batch dimension from predictions\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "        # Apply temperature scaling to logits\n",
    "        predictions = predictions / temperature\n",
    "\n",
    "        # Now predictions are a 1D tensor, so expand the dimension to make it 2D\n",
    "        predictions = tf.expand_dims(predictions, 0)\n",
    "\n",
    "        # Sample the next character from the probability distribution\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
    "\n",
    "        # Add the predicted character to the generated text\n",
    "        generated_text.append(idx_to_char[predicted_id])\n",
    "\n",
    "        # Update the input to include the predicted character\n",
    "        input_eval = np.append(input_eval[:, 1:], np.expand_dims([predicted_id], 0), axis=1)\n",
    "\n",
    "    return start_string + ''.join(generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4332c3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text1(model, start_string, gen_length=10):\n",
    "    input_eval = [char_to_idx[char] for char in start_string]\n",
    "    input_eval = np.expand_dims(input_eval, 0)  # Reshape to match the input shape of the model\n",
    "    generated_text = []\n",
    "\n",
    "    for i in range(gen_length):\n",
    "        predictions = model(input_eval)\n",
    "        # print(predictions.shape)\n",
    "        # print(predictions[0])\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
    "        print(predicted_id)\n",
    "        generated_text.append(idx_to_char[predicted_id])\n",
    "\n",
    "        # Use the predicted character as the next input\n",
    "        input_eval = np.append(input_eval[:, 1:], np.expand_dims([predicted_id], 0), axis=1)\n",
    "\n",
    "    return start_string + ''.join(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8ff6d12a-6225-4d2b-a490-d36212610a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen: let us kill the son the wit the son the love the so\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(generate_text(model, start_string=\"First Citizen: let us kill\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fd0559",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
