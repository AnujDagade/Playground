{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac605650-dad1-479b-affa-ff8d828f4a50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!wget https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9965d9fa-d1bc-42c4-a900-1ea001bbf83d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense, Embedding\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b97e4b08-4a6e-40a1-a75e-e412f4c42536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor\n"
     ]
    }
   ],
   "source": [
    "# Path to the shakespeare.txt file\n",
    "file_path = 'shakespeare.txt'\n",
    "\n",
    "# Open and read the file\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    shakespeare_text = file.read()\n",
    "\n",
    "# Print the first 500 characters (optional, just to preview the content)\n",
    "print(shakespeare_text[:500])  # Adjust as needed to read more or less\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e4843e5-eddd-4233-96d4-529e6d4cfacc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = shakespeare_text\n",
    "chars = sorted(set(text))  # All unique characters\n",
    "char_to_idx = {char: idx for idx, char in enumerate(chars)}  # Mapping from char to index\n",
    "idx_to_char = {idx: char for idx, char in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f98b7a9-9003-456d-9826-e3040a7c5151",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\n': 0, ' ': 1, '!': 2, '$': 3, '&': 4, \"'\": 5, ',': 6, '-': 7, '.': 8, '3': 9, ':': 10, ';': 11, '?': 12, 'A': 13, 'B': 14, 'C': 15, 'D': 16, 'E': 17, 'F': 18, 'G': 19, 'H': 20, 'I': 21, 'J': 22, 'K': 23, 'L': 24, 'M': 25, 'N': 26, 'O': 27, 'P': 28, 'Q': 29, 'R': 30, 'S': 31, 'T': 32, 'U': 33, 'V': 34, 'W': 35, 'X': 36, 'Y': 37, 'Z': 38, 'a': 39, 'b': 40, 'c': 41, 'd': 42, 'e': 43, 'f': 44, 'g': 45, 'h': 46, 'i': 47, 'j': 48, 'k': 49, 'l': 50, 'm': 51, 'n': 52, 'o': 53, 'p': 54, 'q': 55, 'r': 56, 's': 57, 't': 58, 'u': 59, 'v': 60, 'w': 61, 'x': 62, 'y': 63, 'z': 64}\n"
     ]
    }
   ],
   "source": [
    "print(char_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a9999d4f-7450-4e38-98ab-9f0efcd3a77c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seq_length = 10  # Number of characters in each sequence\n",
    "vocab_size = len(chars)  # Size of vocabulary\n",
    "embedding_dim = 64  # Embedding dimensions\n",
    "rnn_units = 128  # Number of RNN units\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "574b8e41-26b1-40f6-b72e-fe5f08c45c01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_sequences(text, seq_length):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(text) - seq_length):\n",
    "        X.append([char_to_idx[char] for char in text[i:i + seq_length]])\n",
    "        y.append(char_to_idx[text[i + seq_length]])\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6c56492c-39ca-4ea5-8dfd-63050276eeab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18 47 56 ... 47 58 47]\n",
      " [47 56 57 ... 58 47 64]\n",
      " [56 57 58 ... 47 64 43]\n",
      " ...\n",
      " [ 1 39 56 ... 49 47 52]\n",
      " [39 56 58 ... 47 52 45]\n",
      " [56 58  1 ... 52 45  8]]\n",
      "[64 43 52 ... 45  8  0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X, y = create_sequences(text, seq_length)\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "51844228-a4d3-4b64-a1f7-23bd9c44ea6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Embedding(input_dim=vocab_size, output_dim=embedding_dim),\n",
    "    SimpleRNN(rnn_units, activation='relu'),  # ReLU activation function\n",
    "    Dense(vocab_size, activation='softmax')  # Softmax for output layer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "899ee7e1-4c5d-49b6-8328-daa1cbc3b819",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3f92a93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this if using tensorflow/keras 2.x\n",
    "\n",
    "# checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "#     filepath='model_weights_epoch_{epoch:02d}.h5',  # Save file with epoch number in the name\n",
    "#     save_weights_only=True,                         # Only save the weights, not the full model\n",
    "#     save_freq='epoch',                              # Save at the end of each epoch\n",
    "#     period=2,                                       # Save every 2 epochs\n",
    "#     verbose=1                                       # Print saving info to the console\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0f7eb789",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_weights_every_2_epochs(epoch, logs):\n",
    "    if (epoch + 1) % 2 == 0:  # Save every 2 epochs\n",
    "        model.save_weights(f'model_weights_epoch_{epoch+1}.weights.h5')\n",
    "        print(f'\\nSaved weights at epoch {epoch+1}')\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=save_weights_every_2_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d4b5825f-aadb-4b4e-8392-3d5cede53dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m  102/34856\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:09\u001b[0m 2ms/step - loss: 1.6011"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 2ms/step - loss: 1.6097\n",
      "Epoch 2/100\n",
      "\u001b[1m34847/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5936\n",
      "Saved weights at epoch 2\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 3ms/step - loss: 1.5936\n",
      "Epoch 3/100\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 2ms/step - loss: 1.5798\n",
      "Epoch 4/100\n",
      "\u001b[1m34837/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5754\n",
      "Saved weights at epoch 4\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 2ms/step - loss: 1.5754\n",
      "Epoch 5/100\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 3ms/step - loss: 1.5703\n",
      "Epoch 6/100\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5655\n",
      "Saved weights at epoch 6\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 3ms/step - loss: 1.5655\n",
      "Epoch 7/100\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 3ms/step - loss: 1.5646\n",
      "Epoch 8/100\n",
      "\u001b[1m34850/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5633\n",
      "Saved weights at epoch 8\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 2ms/step - loss: 1.5633\n",
      "Epoch 9/100\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 2ms/step - loss: 1.5601\n",
      "Epoch 10/100\n",
      "\u001b[1m34850/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5586\n",
      "Saved weights at epoch 10\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 2ms/step - loss: 1.5586\n",
      "Epoch 11/100\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 3ms/step - loss: 1.5547\n",
      "Epoch 12/100\n",
      "\u001b[1m34837/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5565\n",
      "Saved weights at epoch 12\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 3ms/step - loss: 1.5565\n",
      "Epoch 13/100\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 3ms/step - loss: 1.5527\n",
      "Epoch 14/100\n",
      "\u001b[1m34835/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5539\n",
      "Saved weights at epoch 14\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 2ms/step - loss: 1.5539\n",
      "Epoch 15/100\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 2ms/step - loss: 1.5529\n",
      "Epoch 16/100\n",
      "\u001b[1m34855/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5514\n",
      "Saved weights at epoch 16\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 3ms/step - loss: 1.5514\n",
      "Epoch 17/100\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 3ms/step - loss: 1.5537\n",
      "Epoch 18/100\n",
      "\u001b[1m34855/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5499\n",
      "Saved weights at epoch 18\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 3ms/step - loss: 1.5499\n",
      "Epoch 19/100\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 3ms/step - loss: 1.5484\n",
      "Epoch 20/100\n",
      "\u001b[1m34854/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5472\n",
      "Saved weights at epoch 20\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 3ms/step - loss: 1.5472\n",
      "Epoch 21/100\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 3ms/step - loss: 1.5459\n",
      "Epoch 22/100\n",
      "\u001b[1m34841/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5473\n",
      "Saved weights at epoch 22\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 2ms/step - loss: 1.5473\n",
      "Epoch 23/100\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 2ms/step - loss: 1.5449\n",
      "Epoch 24/100\n",
      "\u001b[1m34836/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5461\n",
      "Saved weights at epoch 24\n",
      "\u001b[1m34856/34856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 3ms/step - loss: 1.5461\n",
      "Epoch 25/100\n",
      "\u001b[1m 1326/34856\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:21\u001b[0m 2ms/step - loss: 1.5276"
     ]
    }
   ],
   "source": [
    "model.fit(X, y, batch_size=batch_size, epochs=100, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b9d96d-961a-4870-a3bb-59830247c094",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_rnn_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec03bf4-7b0e-47e4-b511-423f96e35344",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string, gen_length=100, temperature=1.0):\n",
    "    # Convert start_string to numbers (vectorize)\n",
    "    input_eval = [char_to_idx[char] for char in start_string]\n",
    "    input_eval = np.expand_dims(input_eval, 0)  # Add batch dimension\n",
    "\n",
    "    generated_text = []\n",
    "\n",
    "    for i in range(gen_length):\n",
    "        # Get predictions for the current input sequence\n",
    "        predictions = model(input_eval)\n",
    "\n",
    "        # Remove the batch dimension from predictions\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "        # Apply temperature scaling to logits\n",
    "        predictions = predictions / temperature\n",
    "\n",
    "        # Now predictions are a 1D tensor, so expand the dimension to make it 2D\n",
    "        predictions = tf.expand_dims(predictions, 0)\n",
    "\n",
    "        # Sample the next character from the probability distribution\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
    "\n",
    "        # Add the predicted character to the generated text\n",
    "        generated_text.append(idx_to_char[predicted_id])\n",
    "\n",
    "        # Update the input to include the predicted character\n",
    "        input_eval = np.append(input_eval[:, 1:], np.expand_dims([predicted_id], 0), axis=1)\n",
    "\n",
    "    return start_string + ''.join(generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff6d12a-6225-4d2b-a490-d36212610a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(generate_text(model, start_string=\"hello\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
